---
title: 大语言模型（二）：RAG技术
author: mmy83
date: 2024-09-24 09:22:00 +0800
categories: [IT技术, AI]
tags: [AI, 智能体, 大模型, 人工智能, rag, 知识库, 插件, function-calling, 工作流]
math: true
mermaid: true
image:
  path: /images/2024/09/2024-09-24/大语言模型（二）：RAG技术/大语言模型（二）：RAG技术-00.png
  lqip: data:image/webp;base64,UklGRkgAAABXRUJQVlA4IDwAAAAwAgCdASoIAAUAAUAmJZQCdDiAATvzw/s8AAD+/izqIrpV3g0VdcPiW9hVm8faWTLXcOjLLT7RnkGIAAA=
  alt: 大语言模型（二）：RAG技术
---

## 场景

&emsp;&emsp;大模型很火，很多人都希望大模型给自己更多的惊喜。老板希望通过大模型少用人甚至代替员工，员工希望通过大模型减少工作量完成老板的任务。其实都是想让大模型成为生产力。可是现在的大模型似乎远远没有达到预期的效果。到底是预期太高还是大模型本身的问题？这个问题我觉得没有答案，随着时间推移，技术进步，这个答案是变化的。但是当下我觉得他就是一个毕业生的大脑连接了一个键盘（语言大模型）或者再加上一个摄像头（视觉大模型）。他的推理水平取决于哪所学校（厂家）毕业的。他擅长什么领域取决于他的专业（功能）。但是他们都是毕业生的大脑，没手没脚，只有一个屏幕和一些标准接口。

&emsp;&emsp;老板希望通过大模型少用人甚至代替员工，其实就是用毕业生代替人来工作。但是他只是一个毕业生，就算是清华的学生，也不会上来就立刻全会干，也要有一个学习适应的过程。摆在老板面前的两个问题：

一、众多面试毕业生，选择哪个，不同学校的成本不同。有需要支付美刀的，有需要支付人民币的。有使用免费的但是需要高额住房公积金（开源模型），主要需要考虑的是成本和推理能力，按需选择即可。

二、如何在能接受的成本范围内让这个毕业生快速的适应这个工作岗位。这个问题就涉及到技术问题了。有几个选择：

  1、私有化训练：最简单的办法是老板花钱，去专业学校学习，相当于委培。成本自然是最高的，理论上效果会很好，但也有风险可能学傻了。

  2、微调：其次是少花点钱，找个培训机构培训一下。成本稍低，但是效果要看培训机构的教学能力，有点像本科毕业又去培训班学了俩月编程。

  3、RAG：最后是老板不想花钱，于是给毕业生一堆公司资料，让他工作的时候就在这堆资料里找。成本最低，效果就要看资料的内容和毕业生在资料里查找的能力了。

&emsp;&emsp;不是私有化训练花不起，而是RAG更有性价比，好吧，私有化训练确实花不起。大部分公司都会选RAG，毕竟大部分公司都是招现成的毕业生，然后给点公司资料就开干了，招来培训的应该也不多吧，就更别说委培了。

&emsp;&emsp;这里还要先说说这个毕业生大脑的特点（以后随着技术发展可能会有变化）。

1、健忘：你跟他说的话，他记不住。你说的上一句他都不记得。他只能记住当前你和他说的话。

2、没有场景：因为健忘，所有他把自己的场景都忘了。你面试他，你要是不每句话都告诉他这是面试，他都不知道他正在面试。

3、理解能力差：因为没有场景，所有你跟他沟通的时候如果不带上当前场景语境，他可能无法理解你的意思。

4、一次能听的话有限：你说一句可以，但是你给他读一本几百万字的书，他就听不了。但是这个一直在提升。

5、好骗：只要他学到了，你听过各种拐弯抹角的套路他，他就可能把一些私密的东西告诉给你。有点坏叔叔骗小朋友家里保险柜密码的样子。这也是用RAG的一个好处。

## RAG

&emsp;&emsp;检索增强生成（RAG）是一种基于知识库的检索增强方法，它通过将用户查询与知识库中的文档进行匹配来提高生成的质量。

![检索增强生成（RAG）](/images/2024/09/2024-09-24/大语言模型（二）：RAG技术/大语言模型（二）：RAG技术-01.png)

&emsp;&emsp;这张图已经很好的展示了一个简单的RAG原理。我们可以把RAG看作三部分：

![检索增强生成（RAG）三部分](/images/2024/09/2024-09-24/大语言模型（二）：RAG技术/大语言模型（二）：RAG技术-02.png)

### 数据索引

![数据索引](/images/2024/09/2024-09-24/大语言模型（二）：RAG技术/大语言模型（二）：RAG技术-03.png)

&emsp;&emsp;数据索引是一个创建并索引知识库的过程。它通常包括以下步骤：

1、上传知识：上传知识库到RAG中。这个技术上没有啥好说的，但是需要注意知识的格式和质量，更要注意知识的安全性。所有在建设知识库的时候就要考虑知识的权限问题。

2、知识切片：切片其实也是没啥技术含量，但是如何切，切多大却是一个学问。切片的主要原因是提高搜索速度。还有一个关键原因是大模型一次能接收的文本有限，所以需要分片。不能把好几百万字的文档一次提交给大模型。切片的大小取决于大模型一次能接收的文本大小，这个值是固定的。也不能太小，如果太小就影响到知识的语义。

3、向量转化：向量转化就是将知识库中的文档转化为向量的过程。这个过程需要用到一个向量化的模型，这个模型可以是开源的，也可以是私有的。向量转化的目的是为了更好地检索。通过向量转化把文档转化为向量，然后在向量数据库中进行检索。为啥用向量数据库呢，这主要是语义检索的缘故。向量检索可以更好的实现语义检索。

![alt text](/images/2024/09/2024-09-24/大语言模型（二）：RAG技术/大语言模型（二）：RAG技术-04.png)

4、索引数据：将向量化后的数据存到向量数据库中，以备后续检索使用。

### 检索

![知识库检索](/images/2024/09/2024-09-24/大语言模型（二）：RAG技术/大语言模型（二）：RAG技术-05.png)

&emsp;&emsp;当用户输入问题时，首先会对输入的“问题”向量化，然后在向量数据库中查询匹配的结果，通过排序规则对结果进行再次排序（Rerank），最后返回最匹配的结果。这个结果往往数知识库中的文档片段Chunks。应注意长度，加上问题的长度不应过大模型一次能接收的文本大小。

### 生成

&emsp;&emsp;将匹配的Chunks数据和问题通过设计好的提示（Promopt）模板传递给LLM，LLM基于输入的Chunks和问题经过润色加工后返回问题的答案。

## 参考

1、[RAG-大模型的知识库「外挂」｜兼备成本与效益的行业解决方案](https://new.qq.com/rain/a/20240325A020J900)

2、[基于RAG架构搭建医疗智能问答系统（一）](https://news.sohu.com/a/756324130_114819)

3、[langchain官方手册](https://python.langchain.com/v0.2/docs/concepts/)